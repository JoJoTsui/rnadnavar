{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163c69b1",
   "metadata": {},
   "source": [
    "# VCF statistics\n",
    "\n",
    "- Modality specific statistics\n",
    "    - DeepSomatic\n",
    "    - Mutect2\n",
    "    - Strelka\n",
    "- Consensus statistics\n",
    "- Rescue statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e67a6cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# VCF and BAM handling\n",
    "from cyvcf2 import VCF\n",
    "import pysam\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe2ce38",
   "metadata": {},
   "source": [
    "## Configuration and File Discovery\n",
    "\n",
    "Define paths and discover all VCF and alignment files in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb1dbc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFERENCE_FASTA = \"/t9k/mnt/joey/bio_db/references/Homo_sapiens/GATK/GRCh38/Sequence/WholeGenomeFasta/Homo_sapiens_assembly38.fasta\"\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = Path(\"/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset\")\n",
    "\n",
    "# Define file structure\n",
    "TOOLS = [\"deepsomatic\", \"mutect2\", \"strelka\"]\n",
    "MODALITIES = [\"DNA_TUMOR_vs_DNA_NORMAL\", \"RNA_TUMOR_vs_DNA_NORMAL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fac8d145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VCF FILE DISCOVERY SUMMARY\n",
      "================================================================================\n",
      "\n",
      "VARIANT_CALLING:\n",
      "  ✓ deepsomatic_DNA_TUMOR_vs_DNA_NORMAL: DNA_TUMOR_vs_DNA_NORMAL.deepsomatic.vcf.gz\n",
      "  ✓ deepsomatic_RNA_TUMOR_vs_DNA_NORMAL: RNA_TUMOR_vs_DNA_NORMAL.deepsomatic.vcf.gz\n",
      "  ✓ mutect2_DNA_TUMOR_vs_DNA_NORMAL: DNA_TUMOR_vs_DNA_NORMAL.mutect2.vcf.gz\n",
      "  ✓ mutect2_RNA_TUMOR_vs_DNA_NORMAL: RNA_TUMOR_vs_DNA_NORMAL.mutect2.vcf.gz\n",
      "  ✓ strelka_DNA_TUMOR_vs_DNA_NORMAL: DNA_TUMOR_vs_DNA_NORMAL.strelka.variants.vcf.gz\n",
      "  ✓ strelka_RNA_TUMOR_vs_DNA_NORMAL: RNA_TUMOR_vs_DNA_NORMAL.strelka.variants.vcf.gz\n",
      "\n",
      "NORMALIZED:\n",
      "  ✓ deepsomatic_DNA_TUMOR_vs_DNA_NORMAL: DNA_TUMOR_vs_DNA_NORMAL.deepsomatic.variants.dec.norm.vcf.gz\n",
      "  ✓ deepsomatic_RNA_TUMOR_vs_DNA_NORMAL: RNA_TUMOR_vs_DNA_NORMAL.deepsomatic.variants.dec.norm.vcf.gz\n",
      "  ✓ mutect2_DNA_TUMOR_vs_DNA_NORMAL: DNA_TUMOR_vs_DNA_NORMAL.mutect2.variants.dec.norm.vcf.gz\n",
      "  ✓ mutect2_RNA_TUMOR_vs_DNA_NORMAL: RNA_TUMOR_vs_DNA_NORMAL.mutect2.variants.dec.norm.vcf.gz\n",
      "  ✓ strelka_DNA_TUMOR_vs_DNA_NORMAL: DNA_TUMOR_vs_DNA_NORMAL.strelka.variants.dec.norm.vcf.gz\n",
      "  ✓ strelka_RNA_TUMOR_vs_DNA_NORMAL: RNA_TUMOR_vs_DNA_NORMAL.strelka.variants.dec.norm.vcf.gz\n",
      "\n",
      "CONSENSUS:\n",
      "  ✓ DNA_TUMOR_vs_DNA_NORMAL: DNA_TUMOR_vs_DNA_NORMAL.consensus.vcf.gz\n",
      "  ✓ RNA_TUMOR_vs_DNA_NORMAL: RNA_TUMOR_vs_DNA_NORMAL.consensus.vcf.gz\n",
      "\n",
      "RESCUE:\n",
      "  ✓ DNA_TUMOR_vs_DNA_NORMAL_rescued_RNA_TUMOR_vs_DNA_NORMAL: DNA_TUMOR_vs_DNA_NORMAL_rescued_RNA_TUMOR_vs_DNA_NORMAL.rescued.vcf.gz\n",
      "\n",
      "ALIGNMENT FILES:\n",
      "  ✓ DNA_NORMAL: DNA_NORMAL.recal.cram\n",
      "  ✓ DNA_TUMOR: DNA_TUMOR.recal.cram\n",
      "  ✓ RNA_TUMOR: RNA_TUMOR.recal.cram\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "class VCFFileDiscovery:\n",
    "    \"\"\"Discover and organize all VCF files in the pipeline output\"\"\"\n",
    "\n",
    "    def __init__(self, base_dir: Path):\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.vcf_files = {\n",
    "            \"variant_calling\": {},  # Raw tool outputs\n",
    "            \"normalized\": {},  # Normalized VCFs\n",
    "            \"annotated\": {},  # VEP annotated\n",
    "            \"consensus\": {},  # Consensus VCFs\n",
    "            \"rescue\": {},  # Rescue VCFs\n",
    "            \"filtered\": {},  # Filtered VCFs\n",
    "        }\n",
    "        self.alignment_files = {}\n",
    "\n",
    "    def discover_vcfs(self):\n",
    "        \"\"\"Discover all VCF files\"\"\"\n",
    "\n",
    "        # 1. Per-tool variant calling outputs\n",
    "        for tool in TOOLS:\n",
    "            for modality in MODALITIES:\n",
    "                vcf_dir = self.base_dir / \"variant_calling\" / tool / modality\n",
    "                if vcf_dir.exists():\n",
    "                    vcf_files = list(vcf_dir.glob(\"*.vcf.gz\"))\n",
    "                    # Filter out gVCF files\n",
    "                    vcf_files = [f for f in vcf_files if \".g.vcf.gz\" not in str(f)]\n",
    "                    if vcf_files:\n",
    "                        key = f\"{tool}_{modality}\"\n",
    "                        self.vcf_files[\"variant_calling\"][key] = vcf_files[0]\n",
    "\n",
    "        # 2. Normalized VCFs\n",
    "        for tool in TOOLS:\n",
    "            for modality in MODALITIES:\n",
    "                vcf_dir = self.base_dir / \"normalized\" / tool / modality\n",
    "                if vcf_dir.exists():\n",
    "                    vcf_files = list(vcf_dir.glob(\"*.norm.vcf.gz\"))\n",
    "                    if vcf_files:\n",
    "                        key = f\"{tool}_{modality}\"\n",
    "                        self.vcf_files[\"normalized\"][key] = vcf_files[0]\n",
    "\n",
    "        # # 3. Annotated VCFs\n",
    "        # for tool in TOOLS:\n",
    "        #     for modality in MODALITIES:\n",
    "        #         vcf_dir = self.base_dir / \"annotation\" / tool / modality\n",
    "        #         if vcf_dir.exists():\n",
    "        #             vcf_files = list(vcf_dir.glob(\"*VEP.ann.vcf.gz\"))\n",
    "        #             if vcf_files:\n",
    "        #                 key = f\"{tool}_{modality}\"\n",
    "        #                 self.vcf_files[\"annotated\"][key] = vcf_files[0]\n",
    "\n",
    "        # 4. Consensus VCFs\n",
    "        consensus_dir = self.base_dir / \"consensus\" / \"vcf\"\n",
    "        if consensus_dir.exists():\n",
    "            for modality in MODALITIES:\n",
    "                vcf_dir = consensus_dir / modality\n",
    "                if vcf_dir.exists():\n",
    "                    vcf_files = list(vcf_dir.glob(\"*.consensus.vcf.gz\"))\n",
    "                    if vcf_files:\n",
    "                        self.vcf_files[\"consensus\"][modality] = vcf_files[0]\n",
    "\n",
    "        # 5. Rescue VCFs\n",
    "        rescue_dir = self.base_dir / \"rescue\"\n",
    "        if rescue_dir.exists():\n",
    "            for subdir in rescue_dir.iterdir():\n",
    "                if subdir.is_dir():\n",
    "                    vcf_files = list(subdir.glob(\"*.rescued.vcf.gz\"))\n",
    "                    if vcf_files:\n",
    "                        self.vcf_files[\"rescue\"][subdir.name] = vcf_files[0]\n",
    "\n",
    "        # # 6. Filtered VCFs\n",
    "        # filtered_dir = self.base_dir / \"filtered\"\n",
    "        # if filtered_dir.exists():\n",
    "        #     for subdir in filtered_dir.iterdir():\n",
    "        #         if subdir.is_dir():\n",
    "        #             vcf_files = list(subdir.glob(\"*.filtered.vcf.gz\"))\n",
    "        #             if vcf_files:\n",
    "        #                 self.vcf_files[\"filtered\"][subdir.name] = vcf_files[0]\n",
    "\n",
    "        return self.vcf_files\n",
    "\n",
    "    def discover_alignments(self):\n",
    "        \"\"\"Discover alignment files (CRAM/BAM)\"\"\"\n",
    "        recal_dir = self.base_dir / \"preprocessing\" / \"recalibrated\"\n",
    "\n",
    "        if recal_dir.exists():\n",
    "            for sample_dir in recal_dir.iterdir():\n",
    "                if sample_dir.is_dir():\n",
    "                    cram_files = list(sample_dir.glob(\"*.cram\"))\n",
    "                    bam_files = list(sample_dir.glob(\"*.bam\"))\n",
    "\n",
    "                    if cram_files:\n",
    "                        self.alignment_files[sample_dir.name] = cram_files[0]\n",
    "                    elif bam_files:\n",
    "                        self.alignment_files[sample_dir.name] = bam_files[0]\n",
    "\n",
    "        return self.alignment_files\n",
    "\n",
    "    def print_summary(self):\n",
    "        \"\"\"Print discovery summary\"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"VCF FILE DISCOVERY SUMMARY\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        for category, files in self.vcf_files.items():\n",
    "            if files:\n",
    "                print(f\"\\n{category.upper()}:\")\n",
    "                for name, path in files.items():\n",
    "                    print(f\"  ✓ {name}: {path.name}\")\n",
    "\n",
    "        if self.alignment_files:\n",
    "            print(f\"\\nALIGNMENT FILES:\")\n",
    "            for name, path in self.alignment_files.items():\n",
    "                print(f\"  ✓ {name}: {path.name}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "\n",
    "# Discover files\n",
    "discovery = VCFFileDiscovery(BASE_DIR)\n",
    "vcf_files = discovery.discover_vcfs()\n",
    "alignment_files = discovery.discover_alignments()\n",
    "discovery.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "162af317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'variant_calling': {'deepsomatic_DNA_TUMOR_vs_DNA_NORMAL': PosixPath('/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/variant_calling/deepsomatic/DNA_TUMOR_vs_DNA_NORMAL/DNA_TUMOR_vs_DNA_NORMAL.deepsomatic.vcf.gz'),\n",
       "  'deepsomatic_RNA_TUMOR_vs_DNA_NORMAL': PosixPath('/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/variant_calling/deepsomatic/RNA_TUMOR_vs_DNA_NORMAL/RNA_TUMOR_vs_DNA_NORMAL.deepsomatic.vcf.gz'),\n",
       "  'mutect2_DNA_TUMOR_vs_DNA_NORMAL': PosixPath('/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/variant_calling/mutect2/DNA_TUMOR_vs_DNA_NORMAL/DNA_TUMOR_vs_DNA_NORMAL.mutect2.vcf.gz'),\n",
       "  'mutect2_RNA_TUMOR_vs_DNA_NORMAL': PosixPath('/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/variant_calling/mutect2/RNA_TUMOR_vs_DNA_NORMAL/RNA_TUMOR_vs_DNA_NORMAL.mutect2.vcf.gz'),\n",
       "  'strelka_DNA_TUMOR_vs_DNA_NORMAL': PosixPath('/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/variant_calling/strelka/DNA_TUMOR_vs_DNA_NORMAL/DNA_TUMOR_vs_DNA_NORMAL.strelka.variants.vcf.gz'),\n",
       "  'strelka_RNA_TUMOR_vs_DNA_NORMAL': PosixPath('/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/variant_calling/strelka/RNA_TUMOR_vs_DNA_NORMAL/RNA_TUMOR_vs_DNA_NORMAL.strelka.variants.vcf.gz')},\n",
       " 'normalized': {'deepsomatic_DNA_TUMOR_vs_DNA_NORMAL': PosixPath('/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/normalized/deepsomatic/DNA_TUMOR_vs_DNA_NORMAL/DNA_TUMOR_vs_DNA_NORMAL.deepsomatic.variants.dec.norm.vcf.gz'),\n",
       "  'deepsomatic_RNA_TUMOR_vs_DNA_NORMAL': PosixPath('/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/normalized/deepsomatic/RNA_TUMOR_vs_DNA_NORMAL/RNA_TUMOR_vs_DNA_NORMAL.deepsomatic.variants.dec.norm.vcf.gz'),\n",
       "  'mutect2_DNA_TUMOR_vs_DNA_NORMAL': PosixPath('/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/normalized/mutect2/DNA_TUMOR_vs_DNA_NORMAL/DNA_TUMOR_vs_DNA_NORMAL.mutect2.variants.dec.norm.vcf.gz'),\n",
       "  'mutect2_RNA_TUMOR_vs_DNA_NORMAL': PosixPath('/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/normalized/mutect2/RNA_TUMOR_vs_DNA_NORMAL/RNA_TUMOR_vs_DNA_NORMAL.mutect2.variants.dec.norm.vcf.gz'),\n",
       "  'strelka_DNA_TUMOR_vs_DNA_NORMAL': PosixPath('/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/normalized/strelka/DNA_TUMOR_vs_DNA_NORMAL/DNA_TUMOR_vs_DNA_NORMAL.strelka.variants.dec.norm.vcf.gz'),\n",
       "  'strelka_RNA_TUMOR_vs_DNA_NORMAL': PosixPath('/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/normalized/strelka/RNA_TUMOR_vs_DNA_NORMAL/RNA_TUMOR_vs_DNA_NORMAL.strelka.variants.dec.norm.vcf.gz')},\n",
       " 'annotated': {},\n",
       " 'consensus': {'DNA_TUMOR_vs_DNA_NORMAL': PosixPath('/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/consensus/vcf/DNA_TUMOR_vs_DNA_NORMAL/DNA_TUMOR_vs_DNA_NORMAL.consensus.vcf.gz'),\n",
       "  'RNA_TUMOR_vs_DNA_NORMAL': PosixPath('/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/consensus/vcf/RNA_TUMOR_vs_DNA_NORMAL/RNA_TUMOR_vs_DNA_NORMAL.consensus.vcf.gz')},\n",
       " 'rescue': {'DNA_TUMOR_vs_DNA_NORMAL_rescued_RNA_TUMOR_vs_DNA_NORMAL': PosixPath('/t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/rescue/DNA_TUMOR_vs_DNA_NORMAL_rescued_RNA_TUMOR_vs_DNA_NORMAL/DNA_TUMOR_vs_DNA_NORMAL_rescued_RNA_TUMOR_vs_DNA_NORMAL.rescued.vcf.gz')},\n",
       " 'filtered': {}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discovery.vcf_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0121a5e4",
   "metadata": {},
   "source": [
    "## VCF Statistics Extraction\n",
    "\n",
    "Extract comprehensive statistics from VCF files using cyvcf2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3516f733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: DNA_TUMOR_vs_DNA_NORMAL.deepsomatic.vcf.gz\n",
      "Error extracting INFO fields from /t9k/mnt/hdd/work/Vax/sequencing/aim_exp/rdv_test/COO8801.subset/variant_calling/deepsomatic/DNA_TUMOR_vs_DNA_NORMAL/DNA_TUMOR_vs_DNA_NORMAL.deepsomatic.vcf.gz: 'cyvcf2.cyvcf2.HREC' object has no attribute 'get'\n",
      "  ✓ Total variants: 27697\n",
      "  ✓ SNPs: 26353, INDELs: 1344\n",
      "  ✓ Passed filters: 52, Filtered: 27645\n",
      "\n",
      "✓ VCF statistics extraction working!\n"
     ]
    }
   ],
   "source": [
    "class VCFStatisticsExtractor:\n",
    "    \"\"\"Extract comprehensive statistics from VCF files\"\"\"\n",
    "\n",
    "    def __init__(self, vcf_path: Path):\n",
    "        self.vcf_path = vcf_path\n",
    "        self.vcf = None\n",
    "        self.stats = {}\n",
    "\n",
    "    def extract_basic_stats(self):\n",
    "        \"\"\"Extract basic variant statistics\"\"\"\n",
    "        try:\n",
    "            self.vcf = VCF(str(self.vcf_path))\n",
    "\n",
    "            stats = {\n",
    "                \"total_variants\": 0,\n",
    "                \"snps\": 0,\n",
    "                \"indels\": 0,\n",
    "                \"mnps\": 0,\n",
    "                \"complex\": 0,\n",
    "                \"passed\": 0,\n",
    "                \"filtered\": 0,\n",
    "                \"chromosomes\": set(),\n",
    "                \"qualities\": [],\n",
    "                \"variant_types\": defaultdict(int),\n",
    "            }\n",
    "\n",
    "            for variant in self.vcf:\n",
    "                stats[\"total_variants\"] += 1\n",
    "                stats[\"chromosomes\"].add(variant.CHROM)\n",
    "\n",
    "                # Quality scores\n",
    "                if variant.QUAL is not None and variant.QUAL > 0:\n",
    "                    stats[\"qualities\"].append(variant.QUAL)\n",
    "\n",
    "                # Filter status\n",
    "                if (\n",
    "                    variant.FILTER is None\n",
    "                    or variant.FILTER == \"PASS\"\n",
    "                    or variant.FILTER == \".\"\n",
    "                ):\n",
    "                    stats[\"passed\"] += 1\n",
    "                else:\n",
    "                    stats[\"filtered\"] += 1\n",
    "\n",
    "                # Variant type\n",
    "                if variant.is_snp:\n",
    "                    stats[\"snps\"] += 1\n",
    "                    stats[\"variant_types\"][\"SNP\"] += 1\n",
    "                elif variant.is_indel:\n",
    "                    stats[\"indels\"] += 1\n",
    "                    if variant.is_deletion:\n",
    "                        stats[\"variant_types\"][\"DEL\"] += 1\n",
    "                    else:\n",
    "                        stats[\"variant_types\"][\"INS\"] += 1\n",
    "                else:\n",
    "                    stats[\"complex\"] += 1\n",
    "                    stats[\"variant_types\"][\"COMPLEX\"] += 1\n",
    "\n",
    "            stats[\"chromosomes\"] = sorted(list(stats[\"chromosomes\"]))\n",
    "\n",
    "            self.stats[\"basic\"] = stats\n",
    "            return stats\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {self.vcf_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def extract_info_fields(self):\n",
    "        \"\"\"Extract INFO field statistics\"\"\"\n",
    "        try:\n",
    "            if self.vcf is None:\n",
    "                self.vcf = VCF(str(self.vcf_path))\n",
    "\n",
    "            # Get available INFO fields from header\n",
    "            info_fields = {}\n",
    "            for key in self.vcf.header_iter():\n",
    "                if key[\"HeaderType\"] == \"INFO\":\n",
    "                    info_fields[key[\"ID\"]] = {\n",
    "                        \"type\": key.get(\"Type\", \"unknown\"),\n",
    "                        \"values\": [],\n",
    "                    }\n",
    "\n",
    "            # Collect values\n",
    "            variant_count = 0\n",
    "            for variant in self.vcf:\n",
    "                variant_count += 1\n",
    "                for info_id in info_fields.keys():\n",
    "                    try:\n",
    "                        val = variant.INFO.get(info_id)\n",
    "                        if val is not None:\n",
    "                            info_fields[info_id][\"values\"].append(val)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # Limit to first 10000 variants for efficiency\n",
    "                if variant_count > 10000:\n",
    "                    break\n",
    "\n",
    "            # Calculate statistics for numeric fields\n",
    "            info_stats = {}\n",
    "            for info_id, data in info_fields.items():\n",
    "                if data[\"values\"]:\n",
    "                    try:\n",
    "                        # Try to convert to numeric\n",
    "                        numeric_vals = []\n",
    "                        for v in data[\"values\"]:\n",
    "                            if isinstance(v, (list, tuple)):\n",
    "                                numeric_vals.extend(\n",
    "                                    [float(x) for x in v if x is not None]\n",
    "                                )\n",
    "                            else:\n",
    "                                numeric_vals.append(float(v))\n",
    "\n",
    "                        if numeric_vals:\n",
    "                            info_stats[info_id] = {\n",
    "                                \"count\": len(numeric_vals),\n",
    "                                \"mean\": np.mean(numeric_vals),\n",
    "                                \"median\": np.median(numeric_vals),\n",
    "                                \"std\": np.std(numeric_vals),\n",
    "                                \"min\": np.min(numeric_vals),\n",
    "                                \"max\": np.max(numeric_vals),\n",
    "                                \"q25\": np.percentile(numeric_vals, 25),\n",
    "                                \"q75\": np.percentile(numeric_vals, 75),\n",
    "                            }\n",
    "                    except (ValueError, TypeError):\n",
    "                        # Non-numeric field\n",
    "                        info_stats[info_id] = {\n",
    "                            \"count\": len(data[\"values\"]),\n",
    "                            \"type\": \"categorical\",\n",
    "                        }\n",
    "\n",
    "            self.stats[\"info\"] = info_stats\n",
    "            return info_stats\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting INFO fields from {self.vcf_path}: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def extract_format_fields(self):\n",
    "        \"\"\"Extract FORMAT field statistics (sample-level)\"\"\"\n",
    "        try:\n",
    "            if self.vcf is None:\n",
    "                self.vcf = VCF(str(self.vcf_path))\n",
    "\n",
    "            samples = self.vcf.samples\n",
    "            format_stats = {sample: {} for sample in samples}\n",
    "\n",
    "            # Common FORMAT fields to extract\n",
    "            format_fields = [\"DP\", \"AD\", \"AF\", \"GQ\"]\n",
    "\n",
    "            for sample in samples:\n",
    "                for field in format_fields:\n",
    "                    format_stats[sample][field] = []\n",
    "\n",
    "            variant_count = 0\n",
    "            for variant in self.vcf:\n",
    "                variant_count += 1\n",
    "\n",
    "                for i, sample in enumerate(samples):\n",
    "                    # Depth\n",
    "                    try:\n",
    "                        dp = variant.format(\"DP\")[i]\n",
    "                        if dp is not None and dp[0] > 0:\n",
    "                            format_stats[sample][\"DP\"].append(dp[0])\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    # Allelic depth\n",
    "                    try:\n",
    "                        ad = variant.format(\"AD\")[i]\n",
    "                        if ad is not None:\n",
    "                            format_stats[sample][\"AD\"].append(ad)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    # Allele frequency\n",
    "                    try:\n",
    "                        af = variant.format(\"AF\")[i]\n",
    "                        if af is not None and af[0] is not None:\n",
    "                            format_stats[sample][\"AF\"].append(af[0])\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    # Genotype quality\n",
    "                    try:\n",
    "                        gq = variant.format(\"GQ\")[i]\n",
    "                        if gq is not None and gq[0] is not None:\n",
    "                            format_stats[sample][\"GQ\"].append(gq[0])\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # Limit for efficiency\n",
    "                if variant_count > 10000:\n",
    "                    break\n",
    "\n",
    "            # Calculate statistics\n",
    "            format_summary = {}\n",
    "            for sample, fields in format_stats.items():\n",
    "                format_summary[sample] = {}\n",
    "                for field, values in fields.items():\n",
    "                    if values and field != \"AD\":\n",
    "                        format_summary[sample][field] = {\n",
    "                            \"count\": len(values),\n",
    "                            \"mean\": np.mean(values),\n",
    "                            \"median\": np.median(values),\n",
    "                            \"min\": np.min(values),\n",
    "                            \"max\": np.max(values),\n",
    "                            \"q25\": np.percentile(values, 25),\n",
    "                            \"q75\": np.percentile(values, 75),\n",
    "                        }\n",
    "\n",
    "            self.stats[\"format\"] = format_summary\n",
    "            return format_summary\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting FORMAT fields from {self.vcf_path}: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def extract_all_stats(self):\n",
    "        \"\"\"Extract all statistics\"\"\"\n",
    "        print(f\"\\nProcessing: {self.vcf_path.name}\")\n",
    "\n",
    "        basic = self.extract_basic_stats()\n",
    "        info = self.extract_info_fields()\n",
    "        format_stats = self.extract_format_fields()\n",
    "\n",
    "        if basic:\n",
    "            print(f\"  ✓ Total variants: {basic['total_variants']}\")\n",
    "            print(f\"  ✓ SNPs: {basic['snps']}, INDELs: {basic['indels']}\")\n",
    "            print(\n",
    "                f\"  ✓ Passed filters: {basic['passed']}, Filtered: {basic['filtered']}\"\n",
    "            )\n",
    "\n",
    "        return self.stats\n",
    "\n",
    "\n",
    "# Test with one VCF\n",
    "if vcf_files[\"variant_calling\"]:\n",
    "    test_vcf = list(vcf_files[\"variant_calling\"].values())[0]\n",
    "    extractor = VCFStatisticsExtractor(test_vcf)\n",
    "    test_stats = extractor.extract_all_stats()\n",
    "    print(\"\\n✓ VCF statistics extraction working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f89431",
   "metadata": {},
   "source": [
    "## Process All VCF Files\n",
    "\n",
    "Extract statistics from all discovered VCF files across all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_vcfs(vcf_files_dict):\n",
    "    \"\"\"Process all VCF files and collect statistics\"\"\"\n",
    "    all_stats = {}\n",
    "\n",
    "    for category, files in vcf_files_dict.items():\n",
    "        if not files:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"PROCESSING: {category.upper()}\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "\n",
    "        all_stats[category] = {}\n",
    "\n",
    "        for name, vcf_path in files.items():\n",
    "            try:\n",
    "                extractor = VCFStatisticsExtractor(vcf_path)\n",
    "                stats = extractor.extract_all_stats()\n",
    "                all_stats[category][name] = {\"path\": vcf_path, \"stats\": stats}\n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Failed to process {name}: {e}\")\n",
    "\n",
    "    return all_stats\n",
    "\n",
    "\n",
    "# Process all VCFs\n",
    "print(\"Starting comprehensive VCF analysis...\")\n",
    "all_vcf_stats = process_all_vcfs(vcf_files)\n",
    "print(\"\\n✓ All VCF files processed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0645f4",
   "metadata": {},
   "source": [
    "## BAM Alignment Validation\n",
    "\n",
    "Validate variants by checking read support in original BAM/CRAM alignment files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f1a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BAMValidator:\n",
    "    \"\"\"Validate variants using BAM/CRAM alignment files\"\"\"\n",
    "\n",
    "    def __init__(self, reference_fasta: Optional[str] = None):\n",
    "        self.reference_fasta = reference_fasta\n",
    "\n",
    "    def validate_variants(\n",
    "        self, vcf_path: Path, bam_paths: Dict[str, Path], max_variants: int = 100\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Validate variants by checking read support in BAM files\n",
    "\n",
    "        Args:\n",
    "            vcf_path: Path to VCF file\n",
    "            bam_paths: Dictionary mapping sample names to BAM/CRAM paths\n",
    "            max_variants: Maximum number of variants to validate\n",
    "        \"\"\"\n",
    "        validation_results = []\n",
    "\n",
    "        try:\n",
    "            vcf = VCF(str(vcf_path))\n",
    "\n",
    "            # Open BAM files\n",
    "            bam_files = {}\n",
    "            for sample, bam_path in bam_paths.items():\n",
    "                try:\n",
    "                    if self.reference_fasta and str(bam_path).endswith(\".cram\"):\n",
    "                        bam_files[sample] = pysam.AlignmentFile(\n",
    "                            str(bam_path), \"rc\", reference_filename=self.reference_fasta\n",
    "                        )\n",
    "                    else:\n",
    "                        bam_files[sample] = pysam.AlignmentFile(str(bam_path))\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not open {sample} BAM file: {e}\")\n",
    "\n",
    "            if not bam_files:\n",
    "                print(\"No BAM files could be opened for validation\")\n",
    "                return []\n",
    "\n",
    "            # Validate variants\n",
    "            variant_count = 0\n",
    "            for variant in vcf:\n",
    "                if variant_count >= max_variants:\n",
    "                    break\n",
    "\n",
    "                chrom = variant.CHROM\n",
    "                pos = variant.POS\n",
    "                ref = variant.REF\n",
    "                alts = variant.ALT\n",
    "\n",
    "                variant_result = {\n",
    "                    \"chrom\": chrom,\n",
    "                    \"pos\": pos,\n",
    "                    \"ref\": ref,\n",
    "                    \"alt\": \",\".join(alts) if alts else \"\",\n",
    "                    \"qual\": variant.QUAL,\n",
    "                    \"filter\": variant.FILTER if variant.FILTER else \"PASS\",\n",
    "                }\n",
    "\n",
    "                # Check each sample\n",
    "                for sample_name, bam_file in bam_files.items():\n",
    "                    try:\n",
    "                        # Fetch reads covering this position\n",
    "                        pileup_count = 0\n",
    "                        ref_count = 0\n",
    "                        alt_counts = {alt: 0 for alt in alts if alt}\n",
    "                        total_depth = 0\n",
    "\n",
    "                        for pileupcolumn in bam_file.pileup(\n",
    "                            chrom,\n",
    "                            pos - 1,\n",
    "                            pos,\n",
    "                            truncate=True,\n",
    "                            min_base_quality=20,\n",
    "                            max_depth=10000,\n",
    "                        ):\n",
    "                            if pileupcolumn.pos == pos - 1:  # 0-based\n",
    "                                total_depth = pileupcolumn.n\n",
    "\n",
    "                                for pileupread in pileupcolumn.pileups:\n",
    "                                    if (\n",
    "                                        not pileupread.is_del\n",
    "                                        and not pileupread.is_refskip\n",
    "                                    ):\n",
    "                                        base = pileupread.alignment.query_sequence[\n",
    "                                            pileupread.query_position\n",
    "                                        ]\n",
    "\n",
    "                                        if base == ref:\n",
    "                                            ref_count += 1\n",
    "                                        elif base in alt_counts:\n",
    "                                            alt_counts[base] += 1\n",
    "\n",
    "                                        pileup_count += 1\n",
    "\n",
    "                        variant_result[f\"{sample_name}_total_depth\"] = total_depth\n",
    "                        variant_result[f\"{sample_name}_ref_count\"] = ref_count\n",
    "                        for alt, count in alt_counts.items():\n",
    "                            variant_result[f\"{sample_name}_alt_{alt}_count\"] = count\n",
    "\n",
    "                        # Calculate VAF\n",
    "                        if pileup_count > 0:\n",
    "                            total_alt = sum(alt_counts.values())\n",
    "                            vaf = total_alt / pileup_count if pileup_count > 0 else 0\n",
    "                            variant_result[f\"{sample_name}_vaf\"] = vaf\n",
    "                        else:\n",
    "                            variant_result[f\"{sample_name}_vaf\"] = 0\n",
    "\n",
    "                    except Exception as e:\n",
    "                        variant_result[f\"{sample_name}_error\"] = str(e)\n",
    "\n",
    "                validation_results.append(variant_result)\n",
    "                variant_count += 1\n",
    "\n",
    "            # Close BAM files\n",
    "            for bam_file in bam_files.values():\n",
    "                bam_file.close()\n",
    "\n",
    "            return validation_results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during validation: {e}\")\n",
    "            return []\n",
    "\n",
    "    def summarize_validation(self, validation_results: List[Dict]) -> pd.DataFrame:\n",
    "        \"\"\"Convert validation results to DataFrame\"\"\"\n",
    "        if not validation_results:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df = pd.DataFrame(validation_results)\n",
    "        return df\n",
    "\n",
    "\n",
    "# Note: CRAM files require reference genome\n",
    "# If reference is available, set REFERENCE_FASTA path\n",
    "REFERENCE_FASTA = \"/t9k/mnt/joey/bio_db/references/Homo_sapiens/GATK/GRCh38/Sequence/WholeGenomeFasta/Homo_sapiens_assembly38.fasta\"\n",
    "\n",
    "# Check if reference exists\n",
    "if os.path.exists(REFERENCE_FASTA):\n",
    "    print(f\"✓ Reference genome found: {REFERENCE_FASTA}\")\n",
    "    validator = BAMValidator(reference_fasta=REFERENCE_FASTA)\n",
    "else:\n",
    "    print(\"⚠ Reference genome not found at expected location\")\n",
    "    print(\"  BAM validation may not work with CRAM files\")\n",
    "    validator = BAMValidator()\n",
    "\n",
    "print(\"✓ BAM validator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5405dfc4",
   "metadata": {},
   "source": [
    "## Validation Example\n",
    "\n",
    "Example: Validate first 50 variants from a consensus VCF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36309fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Validate DNA consensus VCF\n",
    "if \"DNA_TUMOR_vs_DNA_NORMAL\" in vcf_files.get(\"consensus\", {}):\n",
    "    dna_consensus_vcf = vcf_files[\"consensus\"][\"DNA_TUMOR_vs_DNA_NORMAL\"]\n",
    "\n",
    "    # Map to BAM files\n",
    "    bam_map = {}\n",
    "    if \"DNA_TUMOR\" in alignment_files:\n",
    "        bam_map[\"DNA_TUMOR\"] = alignment_files[\"DNA_TUMOR\"]\n",
    "    if \"DNA_NORMAL\" in alignment_files:\n",
    "        bam_map[\"DNA_NORMAL\"] = alignment_files[\"DNA_NORMAL\"]\n",
    "\n",
    "    if bam_map:\n",
    "        print(f\"Validating {dna_consensus_vcf.name} with alignment files...\")\n",
    "        validation_results = validator.validate_variants(\n",
    "            dna_consensus_vcf, bam_map, max_variants=50\n",
    "        )\n",
    "\n",
    "        if validation_results:\n",
    "            validation_df = validator.summarize_validation(validation_results)\n",
    "            print(f\"\\n✓ Validated {len(validation_results)} variants\")\n",
    "            print(\"\\nFirst few validation results:\")\n",
    "            print(validation_df.head(10))\n",
    "        else:\n",
    "            print(\"No validation results obtained\")\n",
    "    else:\n",
    "        print(\"No alignment files available for validation\")\n",
    "else:\n",
    "    print(\"No consensus VCF found for validation example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722f367a",
   "metadata": {},
   "source": [
    "## Data Aggregation & Summary Statistics\n",
    "\n",
    "Aggregate statistics across all VCF files and create comprehensive summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatisticsAggregator:\n",
    "    \"\"\"Aggregate and summarize VCF statistics\"\"\"\n",
    "\n",
    "    def __init__(self, all_stats: Dict):\n",
    "        self.all_stats = all_stats\n",
    "\n",
    "    def create_variant_count_summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Create summary table of variant counts across all VCFs\"\"\"\n",
    "        rows = []\n",
    "\n",
    "        for category, files in self.all_stats.items():\n",
    "            for name, data in files.items():\n",
    "                if \"stats\" in data and \"basic\" in data[\"stats\"]:\n",
    "                    basic = data[\"stats\"][\"basic\"]\n",
    "\n",
    "                    # Parse tool and modality from name\n",
    "                    parts = name.split(\"_\")\n",
    "                    if len(parts) >= 2:\n",
    "                        tool = parts[0]\n",
    "                        modality = \"_\".join(parts[1:])\n",
    "                    else:\n",
    "                        tool = category\n",
    "                        modality = name\n",
    "\n",
    "                    rows.append(\n",
    "                        {\n",
    "                            \"Category\": category,\n",
    "                            \"Tool\": tool,\n",
    "                            \"Modality\": modality,\n",
    "                            \"Total_Variants\": basic.get(\"total_variants\", 0),\n",
    "                            \"SNPs\": basic.get(\"snps\", 0),\n",
    "                            \"INDELs\": basic.get(\"indels\", 0),\n",
    "                            \"Passed\": basic.get(\"passed\", 0),\n",
    "                            \"Filtered\": basic.get(\"filtered\", 0),\n",
    "                            \"Pass_Rate\": basic.get(\"passed\", 0)\n",
    "                            / basic.get(\"total_variants\", 1)\n",
    "                            if basic.get(\"total_variants\", 0) > 0\n",
    "                            else 0,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        return df.sort_values([\"Category\", \"Tool\", \"Modality\"])\n",
    "\n",
    "    def create_quality_summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Create summary of quality score distributions\"\"\"\n",
    "        rows = []\n",
    "\n",
    "        for category, files in self.all_stats.items():\n",
    "            for name, data in files.items():\n",
    "                if \"stats\" in data and \"basic\" in data[\"stats\"]:\n",
    "                    basic = data[\"stats\"][\"basic\"]\n",
    "                    qualities = basic.get(\"qualities\", [])\n",
    "\n",
    "                    if qualities:\n",
    "                        parts = name.split(\"_\")\n",
    "                        tool = parts[0] if parts else category\n",
    "                        modality = \"_\".join(parts[1:]) if len(parts) > 1 else name\n",
    "\n",
    "                        rows.append(\n",
    "                            {\n",
    "                                \"Category\": category,\n",
    "                                \"Tool\": tool,\n",
    "                                \"Modality\": modality,\n",
    "                                \"Mean_QUAL\": np.mean(qualities),\n",
    "                                \"Median_QUAL\": np.median(qualities),\n",
    "                                \"Min_QUAL\": np.min(qualities),\n",
    "                                \"Max_QUAL\": np.max(qualities),\n",
    "                                \"Q25\": np.percentile(qualities, 25),\n",
    "                                \"Q75\": np.percentile(qualities, 75),\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        return df.sort_values([\"Category\", \"Tool\", \"Modality\"])\n",
    "\n",
    "    def create_info_field_summary(self, info_field: str) -> pd.DataFrame:\n",
    "        \"\"\"Create summary for specific INFO field across all VCFs\"\"\"\n",
    "        rows = []\n",
    "\n",
    "        for category, files in self.all_stats.items():\n",
    "            for name, data in files.items():\n",
    "                if \"stats\" in data and \"info\" in data[\"stats\"]:\n",
    "                    info_stats = data[\"stats\"][\"info\"]\n",
    "\n",
    "                    if info_field in info_stats:\n",
    "                        field_data = info_stats[info_field]\n",
    "\n",
    "                        if isinstance(field_data, dict) and \"mean\" in field_data:\n",
    "                            parts = name.split(\"_\")\n",
    "                            tool = parts[0] if parts else category\n",
    "                            modality = \"_\".join(parts[1:]) if len(parts) > 1 else name\n",
    "\n",
    "                            row = {\n",
    "                                \"Category\": category,\n",
    "                                \"Tool\": tool,\n",
    "                                \"Modality\": modality,\n",
    "                                \"Field\": info_field,\n",
    "                            }\n",
    "                            row.update(field_data)\n",
    "                            rows.append(row)\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        return df.sort_values([\"Category\", \"Tool\", \"Modality\"])\n",
    "\n",
    "    def compare_tools_by_modality(self) -> pd.DataFrame:\n",
    "        \"\"\"Compare variant calling tools within each modality\"\"\"\n",
    "        rows = []\n",
    "\n",
    "        # Focus on variant_calling category\n",
    "        if \"variant_calling\" in self.all_stats:\n",
    "            for name, data in self.all_stats[\"variant_calling\"].items():\n",
    "                if \"stats\" in data and \"basic\" in data[\"stats\"]:\n",
    "                    basic = data[\"stats\"][\"basic\"]\n",
    "                    parts = name.split(\"_\")\n",
    "\n",
    "                    if len(parts) >= 2:\n",
    "                        tool = parts[0]\n",
    "                        modality = \"_\".join(parts[1:])\n",
    "\n",
    "                        rows.append(\n",
    "                            {\n",
    "                                \"Tool\": tool,\n",
    "                                \"Modality\": modality,\n",
    "                                \"Total_Variants\": basic.get(\"total_variants\", 0),\n",
    "                                \"SNPs\": basic.get(\"snps\", 0),\n",
    "                                \"INDELs\": basic.get(\"indels\", 0),\n",
    "                                \"SNP_Ratio\": basic.get(\"snps\", 0)\n",
    "                                / basic.get(\"total_variants\", 1)\n",
    "                                if basic.get(\"total_variants\", 0) > 0\n",
    "                                else 0,\n",
    "                                \"INDEL_Ratio\": basic.get(\"indels\", 0)\n",
    "                                / basic.get(\"total_variants\", 1)\n",
    "                                if basic.get(\"total_variants\", 0) > 0\n",
    "                                else 0,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        return df.sort_values([\"Modality\", \"Tool\"])\n",
    "\n",
    "    def compare_consensus_to_individual(self) -> pd.DataFrame:\n",
    "        \"\"\"Compare consensus VCFs to individual tool outputs\"\"\"\n",
    "        rows = []\n",
    "\n",
    "        # Get consensus counts\n",
    "        consensus_counts = {}\n",
    "        if \"consensus\" in self.all_stats:\n",
    "            for modality, data in self.all_stats[\"consensus\"].items():\n",
    "                if \"stats\" in data and \"basic\" in data[\"stats\"]:\n",
    "                    consensus_counts[modality] = data[\"stats\"][\"basic\"].get(\n",
    "                        \"total_variants\", 0\n",
    "                    )\n",
    "\n",
    "        # Get individual tool counts\n",
    "        if \"variant_calling\" in self.all_stats:\n",
    "            for name, data in self.all_stats[\"variant_calling\"].items():\n",
    "                if \"stats\" in data and \"basic\" in data[\"stats\"]:\n",
    "                    basic = data[\"stats\"][\"basic\"]\n",
    "                    parts = name.split(\"_\")\n",
    "\n",
    "                    if len(parts) >= 2:\n",
    "                        tool = parts[0]\n",
    "                        modality = \"_\".join(parts[1:])\n",
    "                        tool_count = basic.get(\"total_variants\", 0)\n",
    "                        consensus_count = consensus_counts.get(modality, 0)\n",
    "\n",
    "                        rows.append(\n",
    "                            {\n",
    "                                \"Tool\": tool,\n",
    "                                \"Modality\": modality,\n",
    "                                \"Tool_Variants\": tool_count,\n",
    "                                \"Consensus_Variants\": consensus_count,\n",
    "                                \"Difference\": tool_count - consensus_count,\n",
    "                                \"Retention_Rate\": consensus_count / tool_count\n",
    "                                if tool_count > 0\n",
    "                                else 0,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        return df.sort_values([\"Modality\", \"Tool\"])\n",
    "\n",
    "\n",
    "# Create aggregator\n",
    "aggregator = StatisticsAggregator(all_vcf_stats)\n",
    "\n",
    "# Generate summary tables\n",
    "print(\"=\" * 80)\n",
    "print(\"VARIANT COUNT SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "variant_summary = aggregator.create_variant_count_summary()\n",
    "print(variant_summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"QUALITY SCORE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "quality_summary = aggregator.create_quality_summary()\n",
    "print(quality_summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TOOL COMPARISON BY MODALITY\")\n",
    "print(\"=\" * 80)\n",
    "tool_comparison = aggregator.compare_tools_by_modality()\n",
    "print(tool_comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONSENSUS vs INDIVIDUAL TOOLS\")\n",
    "print(\"=\" * 80)\n",
    "consensus_comparison = aggregator.compare_consensus_to_individual()\n",
    "print(consensus_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9642c3",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "Create comprehensive visualizations of VCF statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VCFVisualizer:\n",
    "    \"\"\"Create visualizations for VCF statistics\"\"\"\n",
    "\n",
    "    def __init__(self, all_stats: Dict):\n",
    "        self.all_stats = all_stats\n",
    "\n",
    "    def plot_variant_counts_by_tool(self):\n",
    "        \"\"\"Bar plot comparing variant counts across tools and modalities\"\"\"\n",
    "        data = []\n",
    "\n",
    "        if \"variant_calling\" in self.all_stats:\n",
    "            for name, vcf_data in self.all_stats[\"variant_calling\"].items():\n",
    "                if \"stats\" in vcf_data and \"basic\" in vcf_data[\"stats\"]:\n",
    "                    basic = vcf_data[\"stats\"][\"basic\"]\n",
    "                    parts = name.split(\"_\")\n",
    "                    tool = parts[0] if parts else name\n",
    "                    modality = \"DNA\" if \"DNA_TUMOR\" in name else \"RNA\"\n",
    "\n",
    "                    data.append(\n",
    "                        {\n",
    "                            \"Tool\": tool,\n",
    "                            \"Modality\": modality,\n",
    "                            \"SNPs\": basic.get(\"snps\", 0),\n",
    "                            \"INDELs\": basic.get(\"indels\", 0),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        if not data:\n",
    "            print(\"No data available for plotting\")\n",
    "            return\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Create grouped bar chart\n",
    "        fig = go.Figure()\n",
    "\n",
    "        for modality in df[\"Modality\"].unique():\n",
    "            df_mod = df[df[\"Modality\"] == modality]\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    name=f\"{modality} - SNPs\",\n",
    "                    x=df_mod[\"Tool\"],\n",
    "                    y=df_mod[\"SNPs\"],\n",
    "                    text=df_mod[\"SNPs\"],\n",
    "                    textposition=\"auto\",\n",
    "                )\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    name=f\"{modality} - INDELs\",\n",
    "                    x=df_mod[\"Tool\"],\n",
    "                    y=df_mod[\"INDELs\"],\n",
    "                    text=df_mod[\"INDELs\"],\n",
    "                    textposition=\"auto\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=\"Variant Counts by Tool and Modality\",\n",
    "            xaxis_title=\"Tool\",\n",
    "            yaxis_title=\"Number of Variants\",\n",
    "            barmode=\"group\",\n",
    "            height=500,\n",
    "            template=\"plotly_white\",\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "    def plot_quality_distributions(self):\n",
    "        \"\"\"Box plot of quality score distributions\"\"\"\n",
    "        data = []\n",
    "\n",
    "        for category, files in self.all_stats.items():\n",
    "            for name, vcf_data in files.items():\n",
    "                if \"stats\" in vcf_data and \"basic\" in vcf_data[\"stats\"]:\n",
    "                    qualities = vcf_data[\"stats\"][\"basic\"].get(\"qualities\", [])\n",
    "\n",
    "                    if qualities:\n",
    "                        parts = name.split(\"_\")\n",
    "                        tool = parts[0] if parts else category\n",
    "                        modality = \"DNA\" if \"DNA_TUMOR\" in name else \"RNA\"\n",
    "\n",
    "                        for qual in qualities[:1000]:  # Limit for performance\n",
    "                            data.append(\n",
    "                                {\n",
    "                                    \"Category\": category,\n",
    "                                    \"Tool\": tool,\n",
    "                                    \"Modality\": modality,\n",
    "                                    \"Quality\": qual,\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "        if not data:\n",
    "            print(\"No quality data available\")\n",
    "            return\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        fig = px.box(\n",
    "            df,\n",
    "            x=\"Tool\",\n",
    "            y=\"Quality\",\n",
    "            color=\"Modality\",\n",
    "            facet_col=\"Category\",\n",
    "            title=\"Quality Score Distributions\",\n",
    "            template=\"plotly_white\",\n",
    "            height=500,\n",
    "        )\n",
    "\n",
    "        fig.update_yaxes(title_text=\"QUAL Score\")\n",
    "        fig.show()\n",
    "\n",
    "    def plot_variant_type_distribution(self):\n",
    "        \"\"\"Pie charts showing SNP vs INDEL distribution\"\"\"\n",
    "        fig = make_subplots(\n",
    "            rows=1,\n",
    "            cols=2,\n",
    "            subplot_titles=(\"DNA Modality\", \"RNA Modality\"),\n",
    "            specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}]],\n",
    "        )\n",
    "\n",
    "        if \"variant_calling\" in self.all_stats:\n",
    "            # DNA data\n",
    "            dna_snps = 0\n",
    "            dna_indels = 0\n",
    "            rna_snps = 0\n",
    "            rna_indels = 0\n",
    "\n",
    "            for name, vcf_data in self.all_stats[\"variant_calling\"].items():\n",
    "                if \"stats\" in vcf_data and \"basic\" in vcf_data[\"stats\"]:\n",
    "                    basic = vcf_data[\"stats\"][\"basic\"]\n",
    "\n",
    "                    if \"DNA_TUMOR\" in name:\n",
    "                        dna_snps += basic.get(\"snps\", 0)\n",
    "                        dna_indels += basic.get(\"indels\", 0)\n",
    "                    else:\n",
    "                        rna_snps += basic.get(\"snps\", 0)\n",
    "                        rna_indels += basic.get(\"indels\", 0)\n",
    "\n",
    "            # DNA pie\n",
    "            fig.add_trace(\n",
    "                go.Pie(\n",
    "                    labels=[\"SNPs\", \"INDELs\"],\n",
    "                    values=[dna_snps, dna_indels],\n",
    "                    name=\"DNA\",\n",
    "                    marker_colors=[\"#636EFA\", \"#EF553B\"],\n",
    "                ),\n",
    "                row=1,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "            # RNA pie\n",
    "            fig.add_trace(\n",
    "                go.Pie(\n",
    "                    labels=[\"SNPs\", \"INDELs\"],\n",
    "                    values=[rna_snps, rna_indels],\n",
    "                    name=\"RNA\",\n",
    "                    marker_colors=[\"#636EFA\", \"#EF553B\"],\n",
    "                ),\n",
    "                row=1,\n",
    "                col=2,\n",
    "            )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title_text=\"Variant Type Distribution by Modality\",\n",
    "            height=400,\n",
    "            template=\"plotly_white\",\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "    def plot_consensus_comparison(self):\n",
    "        \"\"\"Compare consensus variants to individual tools\"\"\"\n",
    "        data = []\n",
    "\n",
    "        # Get consensus counts\n",
    "        consensus_counts = {}\n",
    "        if \"consensus\" in self.all_stats:\n",
    "            for modality, vcf_data in self.all_stats[\"consensus\"].items():\n",
    "                if \"stats\" in vcf_data and \"basic\" in vcf_data[\"stats\"]:\n",
    "                    consensus_counts[modality] = vcf_data[\"stats\"][\"basic\"].get(\n",
    "                        \"total_variants\", 0\n",
    "                    )\n",
    "\n",
    "        # Get tool counts\n",
    "        if \"variant_calling\" in self.all_stats:\n",
    "            for name, vcf_data in self.all_stats[\"variant_calling\"].items():\n",
    "                if \"stats\" in vcf_data and \"basic\" in vcf_data[\"stats\"]:\n",
    "                    basic = vcf_data[\"stats\"][\"basic\"]\n",
    "                    parts = name.split(\"_\")\n",
    "                    tool = parts[0] if parts else name\n",
    "                    modality_key = \"_\".join(parts[1:]) if len(parts) > 1 else name\n",
    "\n",
    "                    data.append(\n",
    "                        {\n",
    "                            \"Tool\": tool,\n",
    "                            \"Modality\": \"DNA\" if \"DNA_TUMOR\" in name else \"RNA\",\n",
    "                            \"Tool_Variants\": basic.get(\"total_variants\", 0),\n",
    "                            \"Consensus_Variants\": consensus_counts.get(modality_key, 0),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        if not data:\n",
    "            print(\"No comparison data available\")\n",
    "            return\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Tool variants\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                name=\"Individual Tool\",\n",
    "                x=df[\"Tool\"],\n",
    "                y=df[\"Tool_Variants\"],\n",
    "                marker_color=\"lightblue\",\n",
    "                text=df[\"Tool_Variants\"],\n",
    "                textposition=\"auto\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Consensus variants (only unique values)\n",
    "        unique_consensus = df.drop_duplicates(subset=[\"Modality\"])[\n",
    "            [\"Tool\", \"Consensus_Variants\"]\n",
    "        ]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                name=\"Consensus\",\n",
    "                x=df[\"Tool\"],\n",
    "                y=df[\"Consensus_Variants\"],\n",
    "                mode=\"markers+lines\",\n",
    "                marker=dict(size=12, color=\"red\", symbol=\"diamond\"),\n",
    "                line=dict(color=\"red\", dash=\"dash\"),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=\"Consensus vs Individual Tool Variant Counts\",\n",
    "            xaxis_title=\"Tool\",\n",
    "            yaxis_title=\"Number of Variants\",\n",
    "            template=\"plotly_white\",\n",
    "            height=500,\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "    def plot_filter_status(self):\n",
    "        \"\"\"Stacked bar chart showing pass/filter rates\"\"\"\n",
    "        data = []\n",
    "\n",
    "        for category, files in self.all_stats.items():\n",
    "            for name, vcf_data in files.items():\n",
    "                if \"stats\" in vcf_data and \"basic\" in vcf_data[\"stats\"]:\n",
    "                    basic = vcf_data[\"stats\"][\"basic\"]\n",
    "                    parts = name.split(\"_\")\n",
    "                    tool = parts[0] if parts else category\n",
    "\n",
    "                    data.append(\n",
    "                        {\n",
    "                            \"Category\": category,\n",
    "                            \"Tool\": tool,\n",
    "                            \"Name\": name[:30],  # Truncate for display\n",
    "                            \"Passed\": basic.get(\"passed\", 0),\n",
    "                            \"Filtered\": basic.get(\"filtered\", 0),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        if not data:\n",
    "            print(\"No filter data available\")\n",
    "            return\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Bar(name=\"Passed\", x=df[\"Name\"], y=df[\"Passed\"], marker_color=\"green\")\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Bar(name=\"Filtered\", x=df[\"Name\"], y=df[\"Filtered\"], marker_color=\"red\")\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=\"Filter Status Across VCFs\",\n",
    "            xaxis_title=\"VCF File\",\n",
    "            yaxis_title=\"Number of Variants\",\n",
    "            barmode=\"stack\",\n",
    "            template=\"plotly_white\",\n",
    "            height=500,\n",
    "            xaxis={\"tickangle\": -45},\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "# Create visualizer\n",
    "visualizer = VCFVisualizer(all_vcf_stats)\n",
    "\n",
    "print(\"✓ Visualizer created. Ready to generate plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e432af",
   "metadata": {},
   "source": [
    "### Plot 1: Variant Counts by Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff56d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_variant_counts_by_tool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1dbd84",
   "metadata": {},
   "source": [
    "### Plot 2: Quality Score Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e2738",
   "metadata": {},
   "source": [
    "### Plot 3: Variant Type Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5347cc",
   "metadata": {},
   "source": [
    "### Plot 4: Consensus vs Individual Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea6a6f",
   "metadata": {},
   "source": [
    "### Plot 5: Filter Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026eddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_filter_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33bf299",
   "metadata": {},
   "source": [
    "## Advanced Analysis: Rescue VCF Statistics\n",
    "\n",
    "Analyze the rescue VCFs that combine DNA and RNA modality variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0c21b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_rescue_vcf():\n",
    "    \"\"\"Analyze rescue VCF statistics\"\"\"\n",
    "\n",
    "    if \"rescue\" not in all_vcf_stats or not all_vcf_stats[\"rescue\"]:\n",
    "        print(\"No rescue VCFs found\")\n",
    "        return\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"RESCUE VCF ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for name, data in all_vcf_stats[\"rescue\"].items():\n",
    "        if \"stats\" in data and \"basic\" in data[\"stats\"]:\n",
    "            basic = data[\"stats\"][\"basic\"]\n",
    "\n",
    "            print(f\"\\n{name}:\")\n",
    "            print(f\"  Total rescued variants: {basic.get('total_variants', 0)}\")\n",
    "            print(f\"  SNPs: {basic.get('snps', 0)}\")\n",
    "            print(f\"  INDELs: {basic.get('indels', 0)}\")\n",
    "            print(f\"  Passed filters: {basic.get('passed', 0)}\")\n",
    "            print(f\"  Filtered: {basic.get('filtered', 0)}\")\n",
    "\n",
    "            # Compare with DNA consensus\n",
    "            if \"DNA_TUMOR_vs_DNA_NORMAL\" in all_vcf_stats.get(\"consensus\", {}):\n",
    "                dna_consensus = all_vcf_stats[\"consensus\"][\"DNA_TUMOR_vs_DNA_NORMAL\"]\n",
    "                if \"stats\" in dna_consensus and \"basic\" in dna_consensus[\"stats\"]:\n",
    "                    dna_total = dna_consensus[\"stats\"][\"basic\"].get(\"total_variants\", 0)\n",
    "                    rescue_total = basic.get(\"total_variants\", 0)\n",
    "\n",
    "                    print(f\"\\n  DNA Consensus variants: {dna_total}\")\n",
    "                    print(f\"  After rescue (DNA + RNA): {rescue_total}\")\n",
    "                    print(f\"  Variants added by rescue: {rescue_total - dna_total}\")\n",
    "                    print(\n",
    "                        f\"  Increase: {((rescue_total - dna_total) / dna_total * 100):.1f}%\"\n",
    "                        if dna_total > 0\n",
    "                        else \"N/A\"\n",
    "                    )\n",
    "\n",
    "    # Create comparison plot\n",
    "    if all_vcf_stats[\"rescue\"]:\n",
    "        fig = go.Figure()\n",
    "\n",
    "        categories = []\n",
    "        values = []\n",
    "\n",
    "        # DNA consensus\n",
    "        if \"DNA_TUMOR_vs_DNA_NORMAL\" in all_vcf_stats.get(\"consensus\", {}):\n",
    "            dna_data = all_vcf_stats[\"consensus\"][\"DNA_TUMOR_vs_DNA_NORMAL\"]\n",
    "            if \"stats\" in dna_data and \"basic\" in dna_data[\"stats\"]:\n",
    "                categories.append(\"DNA Consensus\")\n",
    "                values.append(dna_data[\"stats\"][\"basic\"].get(\"total_variants\", 0))\n",
    "\n",
    "        # RNA consensus\n",
    "        if \"RNA_TUMOR_vs_DNA_NORMAL\" in all_vcf_stats.get(\"consensus\", {}):\n",
    "            rna_data = all_vcf_stats[\"consensus\"][\"RNA_TUMOR_vs_DNA_NORMAL\"]\n",
    "            if \"stats\" in rna_data and \"basic\" in rna_data[\"stats\"]:\n",
    "                categories.append(\"RNA Consensus\")\n",
    "                values.append(rna_data[\"stats\"][\"basic\"].get(\"total_variants\", 0))\n",
    "\n",
    "        # Rescue\n",
    "        for name, data in all_vcf_stats[\"rescue\"].items():\n",
    "            if \"stats\" in data and \"basic\" in data[\"stats\"]:\n",
    "                categories.append(\"Rescued (DNA+RNA)\")\n",
    "                values.append(data[\"stats\"][\"basic\"].get(\"total_variants\", 0))\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=categories,\n",
    "                y=values,\n",
    "                text=values,\n",
    "                textposition=\"auto\",\n",
    "                marker_color=[\"skyblue\", \"lightcoral\", \"lightgreen\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=\"Variant Counts: DNA Consensus → RNA Consensus → Rescue\",\n",
    "            xaxis_title=\"VCF Type\",\n",
    "            yaxis_title=\"Number of Variants\",\n",
    "            template=\"plotly_white\",\n",
    "            height=500,\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "analyze_rescue_vcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11357782",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "\n",
    "Export summary statistics to CSV files for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5768c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"vcf_statistics_output\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Export summary tables\n",
    "print(\"Exporting results...\")\n",
    "\n",
    "# 1. Variant count summary\n",
    "variant_summary.to_csv(output_dir / \"variant_count_summary.csv\", index=False)\n",
    "print(f\"✓ Exported: {output_dir / 'variant_count_summary.csv'}\")\n",
    "\n",
    "# 2. Quality summary\n",
    "quality_summary.to_csv(output_dir / \"quality_summary.csv\", index=False)\n",
    "print(f\"✓ Exported: {output_dir / 'quality_summary.csv'}\")\n",
    "\n",
    "# 3. Tool comparison\n",
    "tool_comparison.to_csv(output_dir / \"tool_comparison.csv\", index=False)\n",
    "print(f\"✓ Exported: {output_dir / 'tool_comparison.csv'}\")\n",
    "\n",
    "# 4. Consensus comparison\n",
    "consensus_comparison.to_csv(output_dir / \"consensus_comparison.csv\", index=False)\n",
    "print(f\"✓ Exported: {output_dir / 'consensus_comparison.csv'}\")\n",
    "\n",
    "# 5. Validation results (if available)\n",
    "if \"validation_df\" in locals() and not validation_df.empty:\n",
    "    validation_df.to_csv(output_dir / \"bam_validation_results.csv\", index=False)\n",
    "    print(f\"✓ Exported: {output_dir / 'bam_validation_results.csv'}\")\n",
    "\n",
    "print(f\"\\n✓ All results exported to {output_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b1ec0",
   "metadata": {},
   "source": [
    "## Summary Report\n",
    "\n",
    "Generate a comprehensive summary report of all analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_report():\n",
    "    \"\"\"Generate comprehensive summary report\"\"\"\n",
    "\n",
    "    report = []\n",
    "    report.append(\"=\" * 80)\n",
    "    report.append(\"VCF STATISTICS - COMPREHENSIVE SUMMARY REPORT\")\n",
    "    report.append(\"=\" * 80)\n",
    "    report.append(\"\")\n",
    "\n",
    "    # 1. Overview\n",
    "    report.append(\"## 1. OVERVIEW\")\n",
    "    report.append(\"\")\n",
    "    total_vcfs = sum(len(files) for files in vcf_files.values() if files)\n",
    "    report.append(f\"Total VCF files analyzed: {total_vcfs}\")\n",
    "    report.append(\n",
    "        f\"Categories: {', '.join([cat for cat, files in vcf_files.items() if files])}\"\n",
    "    )\n",
    "    report.append(f\"Tools: {', '.join(TOOLS)}\")\n",
    "    report.append(f\"Modalities: DNA, RNA\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    # 2. Variant Calling Tools Comparison\n",
    "    report.append(\"## 2. VARIANT CALLING TOOLS COMPARISON\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    if not tool_comparison.empty:\n",
    "        report.append(\"### DNA Modality:\")\n",
    "        dna_tools = tool_comparison[\n",
    "            tool_comparison[\"Modality\"].str.contains(\"DNA_TUMOR\")\n",
    "        ]\n",
    "        for _, row in dna_tools.iterrows():\n",
    "            report.append(\n",
    "                f\"  {row['Tool']:12} - {row['Total_Variants']:6} variants \"\n",
    "                f\"(SNPs: {row['SNPs']:5}, INDELs: {row['INDELs']:4})\"\n",
    "            )\n",
    "\n",
    "        report.append(\"\")\n",
    "        report.append(\"### RNA Modality:\")\n",
    "        rna_tools = tool_comparison[\n",
    "            tool_comparison[\"Modality\"].str.contains(\"RNA_TUMOR\")\n",
    "        ]\n",
    "        for _, row in rna_tools.iterrows():\n",
    "            report.append(\n",
    "                f\"  {row['Tool']:12} - {row['Total_Variants']:6} variants \"\n",
    "                f\"(SNPs: {row['SNPs']:5}, INDELs: {row['INDELs']:4})\"\n",
    "            )\n",
    "    report.append(\"\")\n",
    "\n",
    "    # 3. Consensus Analysis\n",
    "    report.append(\"## 3. CONSENSUS ANALYSIS\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    if not consensus_comparison.empty:\n",
    "        for modality in [\"DNA_TUMOR_vs_DNA_NORMAL\", \"RNA_TUMOR_vs_DNA_NORMAL\"]:\n",
    "            mod_name = \"DNA\" if \"DNA_TUMOR\" in modality else \"RNA\"\n",
    "            mod_data = consensus_comparison[\n",
    "                consensus_comparison[\"Modality\"].str.contains(mod_name)\n",
    "            ]\n",
    "\n",
    "            if not mod_data.empty:\n",
    "                consensus_count = mod_data[\"Consensus_Variants\"].iloc[0]\n",
    "                report.append(f\"### {mod_name} Consensus: {consensus_count} variants\")\n",
    "                report.append(\"\")\n",
    "                report.append(\"  Tool contributions:\")\n",
    "                for _, row in mod_data.iterrows():\n",
    "                    retention = row[\"Retention_Rate\"] * 100\n",
    "                    report.append(\n",
    "                        f\"    {row['Tool']:12}: {row['Tool_Variants']:5} variants \"\n",
    "                        f\"→ {retention:5.1f}% retained in consensus\"\n",
    "                    )\n",
    "                report.append(\"\")\n",
    "\n",
    "    # 4. Rescue Statistics\n",
    "    report.append(\"## 4. RESCUE (CROSS-MODALITY) ANALYSIS\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    if \"rescue\" in all_vcf_stats and all_vcf_stats[\"rescue\"]:\n",
    "        for name, data in all_vcf_stats[\"rescue\"].items():\n",
    "            if \"stats\" in data and \"basic\" in data[\"stats\"]:\n",
    "                basic = data[\"stats\"][\"basic\"]\n",
    "                rescue_total = basic.get(\"total_variants\", 0)\n",
    "\n",
    "                # Compare with DNA consensus\n",
    "                if \"DNA_TUMOR_vs_DNA_NORMAL\" in all_vcf_stats.get(\"consensus\", {}):\n",
    "                    dna_consensus = all_vcf_stats[\"consensus\"][\n",
    "                        \"DNA_TUMOR_vs_DNA_NORMAL\"\n",
    "                    ]\n",
    "                    if \"stats\" in dna_consensus and \"basic\" in dna_consensus[\"stats\"]:\n",
    "                        dna_total = dna_consensus[\"stats\"][\"basic\"].get(\n",
    "                            \"total_variants\", 0\n",
    "                        )\n",
    "                        added = rescue_total - dna_total\n",
    "                        pct_increase = (added / dna_total * 100) if dna_total > 0 else 0\n",
    "\n",
    "                        report.append(f\"DNA Consensus: {dna_total} variants\")\n",
    "                        report.append(f\"After RNA rescue: {rescue_total} variants\")\n",
    "                        report.append(f\"Variants added: {added} (+{pct_increase:.1f}%)\")\n",
    "                        report.append(\n",
    "                            f\"SNPs: {basic.get('snps', 0)}, INDELs: {basic.get('indels', 0)}\"\n",
    "                        )\n",
    "    else:\n",
    "        report.append(\"No rescue VCFs found\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    # 5. Quality Metrics\n",
    "    report.append(\"## 5. QUALITY METRICS\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    if not quality_summary.empty:\n",
    "        report.append(\"Average quality scores by tool:\")\n",
    "        for _, row in quality_summary.iterrows():\n",
    "            if row[\"Category\"] == \"variant_calling\":\n",
    "                report.append(\n",
    "                    f\"  {row['Tool']:12} ({row['Modality'][:3]}): \"\n",
    "                    f\"Mean={row['Mean_QUAL']:7.2f}, Median={row['Median_QUAL']:7.2f}\"\n",
    "                )\n",
    "    report.append(\"\")\n",
    "\n",
    "    # 6. Filter Status\n",
    "    report.append(\"## 6. FILTER STATUS SUMMARY\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    total_passed = variant_summary[\"Passed\"].sum()\n",
    "    total_filtered = variant_summary[\"Filtered\"].sum()\n",
    "    total_all = total_passed + total_filtered\n",
    "    pass_rate = (total_passed / total_all * 100) if total_all > 0 else 0\n",
    "\n",
    "    report.append(f\"Total variants across all VCFs: {total_all}\")\n",
    "    report.append(f\"  Passed filters: {total_passed} ({pass_rate:.1f}%)\")\n",
    "    report.append(f\"  Filtered out: {total_filtered} ({100 - pass_rate:.1f}%)\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    # 7. Recommendations\n",
    "    report.append(\"## 7. KEY INSIGHTS\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    if not tool_comparison.empty:\n",
    "        # Find most/least sensitive tool\n",
    "        dna_tools = tool_comparison[\n",
    "            tool_comparison[\"Modality\"].str.contains(\"DNA_TUMOR\")\n",
    "        ]\n",
    "        if not dna_tools.empty:\n",
    "            most_sensitive = dna_tools.loc[dna_tools[\"Total_Variants\"].idxmax()]\n",
    "            least_sensitive = dna_tools.loc[dna_tools[\"Total_Variants\"].idxmin()]\n",
    "\n",
    "            report.append(\n",
    "                f\"• Most sensitive tool (DNA): {most_sensitive['Tool']} \"\n",
    "                f\"({most_sensitive['Total_Variants']} variants)\"\n",
    "            )\n",
    "            report.append(\n",
    "                f\"• Most conservative tool (DNA): {least_sensitive['Tool']} \"\n",
    "                f\"({least_sensitive['Total_Variants']} variants)\"\n",
    "            )\n",
    "            report.append(\"\")\n",
    "\n",
    "    if \"rescue\" in all_vcf_stats and all_vcf_stats[\"rescue\"]:\n",
    "        report.append(\n",
    "            \"• Cross-modality rescue successfully recovered additional variants from RNA data\"\n",
    "        )\n",
    "        report.append(\n",
    "            \"• RNA sequencing provides complementary variant detection to DNA\"\n",
    "        )\n",
    "\n",
    "    report.append(\"\")\n",
    "    report.append(\"=\" * 80)\n",
    "    report.append(\"END OF REPORT\")\n",
    "    report.append(\"=\" * 80)\n",
    "\n",
    "    # Print report\n",
    "    report_text = \"\\n\".join(report)\n",
    "    print(report_text)\n",
    "\n",
    "    # Save report\n",
    "    with open(output_dir / \"summary_report.txt\", \"w\") as f:\n",
    "        f.write(report_text)\n",
    "\n",
    "    print(f\"\\n✓ Report saved to {output_dir / 'summary_report.txt'}\")\n",
    "\n",
    "    return report_text\n",
    "\n",
    "\n",
    "# Generate report\n",
    "summary_report = generate_summary_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd77a3e8",
   "metadata": {},
   "source": [
    "## Usage Guide & Next Steps\n",
    "\n",
    "### What This Notebook Does\n",
    "\n",
    "This comprehensive VCF statistics notebook provides:\n",
    "\n",
    "1. **File Discovery** - Automatically finds all VCF files across your pipeline\n",
    "2. **Statistics Extraction** - Uses cyvcf2 to extract:\n",
    "   - Variant counts (SNPs, INDELs, complex)\n",
    "   - Quality scores and distributions\n",
    "   - INFO field statistics (DP, AF, TLOD, etc.)\n",
    "   - FORMAT field statistics (per-sample depth, allele frequency, genotype quality)\n",
    "   - Filter status\n",
    "\n",
    "3. **BAM Validation** - Uses pysam to:\n",
    "   - Cross-reference variants with alignment files\n",
    "   - Calculate read support (ref/alt counts)\n",
    "   - Validate variant allele frequencies (VAF)\n",
    "\n",
    "4. **Comprehensive Analysis**:\n",
    "   - Tool comparison (DeepSomatic, Mutect2, Strelka)\n",
    "   - Modality comparison (DNA vs RNA)\n",
    "   - Consensus analysis (agreement across tools)\n",
    "   - Rescue analysis (cross-modality variant recovery)\n",
    "\n",
    "5. **Visualizations**:\n",
    "   - Interactive Plotly charts\n",
    "   - Quality distributions\n",
    "   - Variant type breakdowns\n",
    "   - Tool performance comparisons\n",
    "\n",
    "6. **Export** - All results saved as CSV files\n",
    "\n",
    "### How to Customize\n",
    "\n",
    "**Change base directory:**\n",
    "```python\n",
    "BASE_DIR = Path(\"/your/custom/path\")\n",
    "```\n",
    "\n",
    "**Validate more/fewer variants:**\n",
    "```python\n",
    "validation_results = validator.validate_variants(vcf, bam_map, max_variants=100)\n",
    "```\n",
    "\n",
    "**Add custom INFO field analysis:**\n",
    "```python\n",
    "tlod_summary = aggregator.create_info_field_summary('TLOD')\n",
    "print(tlod_summary)\n",
    "```\n",
    "\n",
    "**Analyze specific tools only:**\n",
    "```python\n",
    "TOOLS = ['mutect2', 'deepsomatic']  # Remove strelka\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Run all cells** to generate complete analysis\n",
    "2. **Check `vcf_statistics_output/`** for exported CSVs\n",
    "3. **Customize visualizations** for your specific needs\n",
    "4. **Extend BAM validation** to more samples/variants\n",
    "5. **Add INFO field analysis** for tool-specific metrics (TLOD, NLOD, etc.)\n",
    "\n",
    "### Advanced Usage\n",
    "\n",
    "**Analyze specific INFO fields:**\n",
    "```python\n",
    "# Example: Tumor LOD scores\n",
    "tlod_stats = aggregator.create_info_field_summary('TLOD')\n",
    "```\n",
    "\n",
    "**Custom validation:**\n",
    "```python\n",
    "# Validate specific chromosomes or regions\n",
    "validation_results = validator.validate_variants(\n",
    "    vcf_path, \n",
    "    bam_paths,\n",
    "    max_variants=200  # More variants\n",
    ")\n",
    "```\n",
    "\n",
    "**Cross-sample comparison:**\n",
    "```python\n",
    "# Compare tumor vs normal depths\n",
    "format_stats = extractor.extract_format_fields()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b24e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_consensus_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e84722",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_variant_type_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46bdd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_quality_distributions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnadnavar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
